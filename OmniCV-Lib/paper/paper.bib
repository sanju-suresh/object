@Inbook{Scaramuzza2014,
author="Scaramuzza, Davide",
editor="Ikeuchi, Katsushi",
title="Omnidirectional Camera",
bookTitle="Computer Vision: A Reference Guide",
year="2014",
publisher="Springer US",
address="Boston, MA",
pages="552--560",
isbn="978-0-387-31439-6",
doi="10.1007/978-0-387-31439-6_488",
url="https://doi.org/10.1007/978-0-387-31439-6_488"
}

@inproceedings{Zhang2016BenefitOL,
author = {Zhang, Zichao and Rebecq, Henri and Forster, Christian and Scaramuzza, Davide},
year = {2016},
month = {05},
pages = {801-808},
title = {Benefit of large field-of-view cameras for visual odometry},
doi = {10.1109/ICRA.2016.7487210}
}

@inproceedings{inproceedings,
author = {Bogdan, Oleksandr and Eckstein, Viktor and Rameau, François and Bazin, Jean-Charles},
year = {2018},
month = {12},
pages = {1-10},
title = {DeepCalib: a deep learning approach for automatic intrinsic calibration of wide field-of-view cameras},
doi = {10.1145/3278471.3278479}
}

@article{Barreto2006,
author = {Barreto, Joao P},
year = {2006},
month = {09},
pages = {208-217},
title = {A unifying geometric representation for central projection systems},
volume = {103},
journal = {Computer Vision and Image Understanding},
doi = {10.1016/j.cviu.2006.06.003}
}

@incollection{NIPS2017_6656,
title = {Learning Spherical Convolution for Fast Features from 360\textdegree  Imagery},
author = {Su, Yu-Chuan and Grauman, Kristen},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {529--539},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6656-learning-spherical-convolution-for-fast-features-from-360-imagery.pdf}
}

@misc{wang2018cubemapslam,
    title={CubemapSLAM: A Piecewise-Pinhole Monocular Fisheye SLAM System},
    author={Yahui Wang and Shaojun Cai and Shi-Jie Li and Yun Liu and Yangyan Guo and Tao Li and Ming-Ming Cheng},
    year={2018},
    eprint={1811.12633},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    doi = {10.1007/978-3-030-20876-9_3}
}


@InProceedings{usenko18double-sphere,
  author = "V. Usenko and N. Demmel and D. Cremers",
  title = "The Double Sphere Camera Model",
  booktitle = {Proc. of the Int. Conference on 3D Vision (3DV)},
  year = "2018",
  month = "September",
  eprint = {1807.08957},
  eprinttype = {arXiv},
  eprintclass = {cs.CV},
  note = {{<a href="https://arxiv.org/abs/1807.08957" target="_blank">[arxiv]</a>}},
  keywords = double-sphere,
  doi = {10.1109/3DV.2018.00069}
}

@inproceedings{UCM,
author = {Geyer, Christopher and Daniilidis, Kostas},
year = {2000},
month = {04},
pages = {},
title = {A Unifying Theory for Central Panoramic Systems and Practical Implications},
journal = {ECCV},
doi = {10.1007/3-540-45053-X_29}
}

@ARTICLE{EUCM,
  author={B. {Khomutenko} and G. {Garcia} and P. {Martinet}},
  journal={IEEE Robotics and Automation Letters}, 
  title={An Enhanced Unified Camera Model}, 
  year={2016},
  volume={1},
  number={1},
  pages={137-144},}

@article{FOV,
author = {Devernay, Frédéric and Faugeras, Olivier},
year = {2001},
month = {08},
pages = {},
title = {Straight Lines Have to Be Straight Automatic Calibration and Removal of Distortion from Scenes of Structured Environments},
volume = {13},
journal = {Mach Vis Appl},
doi = {10.1007/PL00013269}
}

@INPROCEEDINGS{FisheyeDataset,
author={A. {Eichenseer} and A. {Kaup}},
booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={A data set providing synthetic and real-world fisheye video sequences},
year={2016},
volume={},  number={},  pages={1541-1545},
doi = {10.1109/ICASSP.2016.7471935}}

@misc{py360convert,
title={py360convert},
howpublished = {\url{https://github.com/sunset1995/py360convert}}
}

@misc{fisheyedwarp,
title={fisheyedwarp},
howpublished = {\url{https://github.com/BlueHorn07/py-fisheye-dewarp}}
}
 
@article{NumPy,
  author    = {Stéfan van der Walt and S. Chris Colbert and Gaël Varoquaux},
  title     = {The NumPy Array: A Structure for Efficient Numerical Computation},
  journal   = {Computing in Science \& Engineering},
  volume    = {13},
  pages     = {22-30},
  year      = {2011},
  doi       = {10.1109/MCSE.2011.37},
  url       = {http://www.numpy.org},
}

@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing In Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python
  for application development, interactive scripting, and
  publication-quality image generation across user
  interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi = {10.1109/MCSE.2007.55},
  year      = 2007
}
  
@inproceedings{soton403913,
       booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
          editor = {Fernando Loizides and Birgit Scmidt},
           title = {Jupyter Notebooks ? a publishing format for reproducible computational workflows},
          author = {Thomas Kluyver and Benjamin Ragan-Kelley and Fernando P{\'e}rez and Brian Granger and Matthias Bussonnier and Jonathan Frederic and Kyle Kelley and Jessica Hamrick and Jason Grout and Sylvain Corlay and Paul Ivanov and Dami{\'a}n Avila and Safia Abdalla and Carol Willing and  Jupyter development team},
       publisher = {IOS Press},
            year = {2016},
           pages = {87--90},
             url = {https://eprints.soton.ac.uk/403913/},
        abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.}
}

@misc{opencv,
  title={{Open} {Source} {Computer} {Vision} {Library}},
  year={2015},
  howpublished = {\url{https://opencv.org}}
}
